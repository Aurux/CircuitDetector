{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81c9974d",
   "metadata": {},
   "source": [
    "# Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dd90b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 12:33:57.069906: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os, object_detection\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c556a5",
   "metadata": {},
   "source": [
    "## Set up file structure and download chosen base model from Model Zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d3c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"640x640_model\"\n",
    "pretrainedModel = \"ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8\"\n",
    "pretrainedModelURL = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\"\n",
    "\n",
    "# Script sourced from Tensorflow: https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/tensorflow-1.14/training.html\n",
    "tfRecordScript = \"generate_tfrecord.py\"\n",
    "labelMap = \"label_map.pbtxt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e92e56ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "filePaths = {\n",
    "    \"WORKSPACE\": os.path.join(\"TF\", \"workspace\"),\n",
    "    \"SCRIPTS\": os.path.join(\"TF\", \"scripts\"),\n",
    "    \"APIMODEL\": os.path.join(\"TF\", \"models\"),\n",
    "    \"ANNOTATIONS\": os.path.join(\"TF\", \"workspace\", \"annotations\"),\n",
    "    \"IMAGES\": os.path.join(\"TF\", \"workspace\", \"images\"),\n",
    "    \"PRETRAINED_MODELS\": os.path.join(\"TF\", \"workspace\", \"pretrained_models\"),\n",
    "    'MODELS': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'CHECKPOINTS': os.path.join('Tensorflow', 'workspace','models', modelName), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f3fe509",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', modelName, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(filePaths['SCRIPTS'], tfRecordScript),\n",
    "    'LABELMAP': os.path.join(filePaths['ANNOTATIONS'], labelMap)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb2641ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in filePaths.values():\n",
    "    !mkdir -p {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37aac0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'TF/models'...\n",
      "remote: Enumerating objects: 81991, done.\u001b[K\n",
      "remote: Counting objects: 100% (458/458), done.\u001b[K\n",
      "remote: Compressing objects: 100% (204/204), done.\u001b[K\n",
      "remote: Total 81991 (delta 293), reused 400 (delta 254), pack-reused 81533\u001b[K\n",
      "Receiving objects: 100% (81991/81991), 596.38 MiB | 5.53 MiB/s, done.\n",
      "Resolving deltas: 100% (58482/58482), done.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join(filePaths['APIMODEL'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {filePaths['APIMODEL']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acc50088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-09 12:57:47--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.200.16, 2a00:1450:4009:81d::2010\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.200.16|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20518283 (20M) [application/x-tar]\n",
      "Saving to: ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’\n",
      "\n",
      "ssd_mobilenet_v2_fp 100%[===================>]  19.57M  34.4MB/s    in 0.6s    \n",
      "\n",
      "2023-03-09 12:57:48 (34.4 MB/s) - ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’ saved [20518283/20518283]\n",
      "\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "!wget {pretrainedModelURL}\n",
    "!mv {pretrainedModel+'.tar.gz'} {filePaths['PRETRAINED_MODELS']}\n",
    "!cd {filePaths['PRETRAINED_MODELS']} && tar -zxvf {pretrainedModel+'.tar.gz'}\n",
    "!cp {os.path.join(filePaths['PRETRAINED_MODELS'], pretrainedModel, 'pipeline.config')} {os.path.join(filePaths['CHECKPOINTS'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b7949",
   "metadata": {},
   "source": [
    "# Create label mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7345cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectLabels = [{'name':'resistor', 'id':1},\n",
    "                {'name':'electrolytic_capacitor', 'id':2},\n",
    "                {'name':'LED', 'id':3},\n",
    "                {'name':'ceramic_capacitor', 'id':4},\n",
    "                {'name':'IC', 'id':5}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in objectLabels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2be037e",
   "metadata": {},
   "source": [
    "## Convert XML to TF record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d638fff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: TF/workspace/annotations/train.record\n",
      "Successfully created the TFRecord file: TF/workspace/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(filePaths['IMAGES'], 'train')} -l {files['LABELMAP']} -o {os.path.join(filePaths['ANNOTATIONS'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(filePaths['IMAGES'], 'test')} -l {files['LABELMAP']} -o {os.path.join(filePaths['ANNOTATIONS'], 'test.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de8ff1a",
   "metadata": {},
   "source": [
    "## Set up model config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4af93b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)\n",
    "    \n",
    "pipeline_config.model.ssd.num_classes = len(objectLabels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(filePaths['PRETRAINED_MODELS'], pretrainedModel, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(filePaths['ANNOTATIONS'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(filePaths['ANNOTATIONS'], 'test.record')]\n",
    "\n",
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30297006",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "774f5247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-09 13:27:59.667871: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-09 13:28:01.224458: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 13:28:01.226028: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 13:28:01.226152: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 13:28:01.226491: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-09 13:28:01.227087: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 13:28:01.227209: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 13:28:01.227318: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 13:28:01.500988: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 13:28:01.501112: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 13:28:01.501200: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 13:28:01.501278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8297 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:0a:00.0, compute capability: 8.6\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I0309 13:28:01.564630 139794484254528 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 5\n",
      "I0309 13:28:01.566664 139794484254528 config_util.py:552] Maybe overwriting train_steps: 5\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0309 13:28:01.566712 139794484254528 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0309 13:28:01.579848 139794484254528 deprecation.py:350] From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['TF/workspace/annotations/train.record']\n",
      "I0309 13:28:01.583588 139794484254528 dataset_builder.py:162] Reading unweighted datasets: ['TF/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['TF/workspace/annotations/train.record']\n",
      "I0309 13:28:01.583652 139794484254528 dataset_builder.py:79] Reading record datasets for input file: ['TF/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0309 13:28:01.583686 139794484254528 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0309 13:28:01.583713 139794484254528 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0309 13:28:01.586753 139794484254528 deprecation.py:350] From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0309 13:28:01.594826 139794484254528 deprecation.py:350] From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0309 13:28:01.899959 139794484254528 deprecation.py:350] From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:tensorflow:From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0309 13:28:04.949534 139794484254528 deprecation.py:350] From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0309 13:28:06.337535 139794484254528 deprecation.py:350] From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0309 13:28:07.140437 139794484254528 deprecation.py:350] From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "/home/ben/.conda/envs/tf/lib/python3.10/site-packages/keras/backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n",
      "2023-03-09 13:28:19.668098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8800\n",
      "2023-03-09 13:28:20.358628: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "W0309 13:28:22.332612 139794484254528 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "W0309 13:28:22.332731 139794484254528 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "W0309 13:28:22.332764 139794484254528 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum\n",
      "W0309 13:28:22.332790 139794484254528 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.momentum\n",
      "Training time: 23.58 seconds! (0.0 minutes)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "trainerScript = os.path.join(filePaths['APIMODEL'], 'research', 'object_detection', 'model_main_tf2.py')\n",
    "\n",
    "trainCommand = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=5000\".format(trainerScript, filePaths['CHECKPOINTS'],files['PIPELINE_CONFIG'])\n",
    "\n",
    "# Trained using an Nvidia RTX 3060 GPU (12GB VRAM) for acceleration.\n",
    "start = time.time()\n",
    "!{trainCommand}\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "elapsedMins = elapsed / 60\n",
    "print(\"Training time: {} seconds! ({} minutes)\".format(round(elapsed, 2), round(elapsedMins, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4f6d76",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e603a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-09 13:28:40.171545: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-09 13:28:41.866017: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 13:28:41.867680: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 13:28:41.867791: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W0309 13:28:41.869499 140694009034560 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "I0309 13:28:41.869584 140694009034560 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0309 13:28:41.869616 140694009034560 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I0309 13:28:41.869644 140694009034560 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W0309 13:28:41.869682 140694009034560 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "2023-03-09 13:28:41.871563: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-09 13:28:41.872139: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 13:28:41.872247: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 13:28:41.872337: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 13:28:42.172329: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 13:28:42.172459: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 13:28:42.172545: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 13:28:42.172625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8270 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:0a:00.0, compute capability: 8.6\n",
      "INFO:tensorflow:Reading unweighted datasets: ['TF/workspace/annotations/test.record']\n",
      "I0309 13:28:42.256089 140694009034560 dataset_builder.py:162] Reading unweighted datasets: ['TF/workspace/annotations/test.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['TF/workspace/annotations/test.record']\n",
      "I0309 13:28:42.256216 140694009034560 dataset_builder.py:79] Reading record datasets for input file: ['TF/workspace/annotations/test.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0309 13:28:42.256258 140694009034560 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0309 13:28:42.256285 140694009034560 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0309 13:28:42.258229 140694009034560 deprecation.py:350] From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0309 13:28:42.267271 140694009034560 deprecation.py:350] From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "W0309 13:28:42.592233 140694009034560 deprecation.py:350] From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:tensorflow:From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0309 13:28:44.372179 140694009034560 deprecation.py:350] From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0309 13:28:44.843819 140694009034560 deprecation.py:350] From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/640x640_model\n",
      "I0309 13:28:46.100950 140694009034560 checkpoint_utils.py:140] Waiting for new checkpoint at Tensorflow/workspace/models/640x640_model\n",
      "INFO:tensorflow:Found new checkpoint at Tensorflow/workspace/models/640x640_model/ckpt-6\n",
      "I0309 13:28:46.101377 140694009034560 checkpoint_utils.py:149] Found new checkpoint at Tensorflow/workspace/models/640x640_model/ckpt-6\n",
      "/home/ben/.conda/envs/tf/lib/python3.10/site-packages/keras/backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n",
      "2023-03-09 13:28:57.670070: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8800\n",
      "2023-03-09 13:28:57.675081: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "WARNING:tensorflow:From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0309 13:28:58.937731 140694009034560 deprecation.py:350] From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Finished eval step 0\n",
      "I0309 13:28:58.953664 140694009034560 model_lib_v2.py:966] Finished eval step 0\n",
      "WARNING:tensorflow:From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W0309 13:28:59.033270 140694009034560 deprecation.py:350] From /home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "INFO:tensorflow:Performing evaluation on 2 images.\n",
      "I0309 13:28:59.734576 140694009034560 coco_evaluation.py:293] Performing evaluation on 2 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0309 13:28:59.734741 140694009034560 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I0309 13:28:59.735102 140694009034560 coco_tools.py:138] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.722\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.871\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.675\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.376\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.735\n",
      "INFO:tensorflow:Eval metrics at step 5000\n",
      "I0309 13:28:59.754463 140694009034560 model_lib_v2.py:1015] Eval metrics at step 5000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.722376\n",
      "I0309 13:28:59.757100 140694009034560 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.722376\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 1.000000\n",
      "I0309 13:28:59.757606 140694009034560 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.871287\n",
      "I0309 13:28:59.758086 140694009034560 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.871287\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
      "I0309 13:28:59.758563 140694009034560 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.675248\n",
      "I0309 13:28:59.759040 140694009034560 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.675248\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.728944\n",
      "I0309 13:28:59.759517 140694009034560 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.728944\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.376286\n",
      "I0309 13:28:59.760110 140694009034560 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.376286\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.733429\n",
      "I0309 13:28:59.760626 140694009034560 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.733429\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.733429\n",
      "I0309 13:28:59.761776 140694009034560 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.733429\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
      "I0309 13:28:59.762356 140694009034560 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.700000\n",
      "I0309 13:28:59.762886 140694009034560 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.700000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.735000\n",
      "I0309 13:28:59.763501 140694009034560 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.735000\n",
      "INFO:tensorflow:\t+ Loss/localization_loss: 0.205884\n",
      "I0309 13:28:59.763915 140694009034560 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.205884\n",
      "INFO:tensorflow:\t+ Loss/classification_loss: 0.340775\n",
      "I0309 13:28:59.764398 140694009034560 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.340775\n",
      "INFO:tensorflow:\t+ Loss/regularization_loss: 0.119716\n",
      "I0309 13:28:59.764838 140694009034560 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.119716\n",
      "INFO:tensorflow:\t+ Loss/total_loss: 0.666375\n",
      "I0309 13:28:59.765261 140694009034560 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.666375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ben/Documents/Computer_Science/Hope/Core2/CircuitDetector/TF/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\r\n",
      "    tf.compat.v1.app.run()\r\n",
      "  File \"/home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/platform/app.py\", line 36, in run\r\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n",
      "  File \"/home/ben/.conda/envs/tf/lib/python3.10/site-packages/absl/app.py\", line 308, in run\r\n",
      "    _run_main(main, args)\r\n",
      "  File \"/home/ben/.conda/envs/tf/lib/python3.10/site-packages/absl/app.py\", line 254, in _run_main\r\n",
      "    sys.exit(main(argv))\r\n",
      "  File \"/home/ben/Documents/Computer_Science/Hope/Core2/CircuitDetector/TF/models/research/object_detection/model_main_tf2.py\", line 81, in main\r\n",
      "    model_lib_v2.eval_continuously(\r\n",
      "  File \"/home/ben/.conda/envs/tf/lib/python3.10/site-packages/object_detection/model_lib_v2.py\", line 1135, in eval_continuously\r\n",
      "    for latest_checkpoint in tf.train.checkpoints_iterator(\r\n",
      "  File \"/home/ben/.conda/envs/tf/lib/python3.10/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 216, in checkpoints_iterator\r\n",
      "    time.sleep(time_to_next_eval)\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "evalCommand = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(trainerScript, filePaths['CHECKPOINTS'],files['PIPELINE_CONFIG'], filePaths['CHECKPOINTS'])\n",
    "\n",
    "!{evalCommand}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86ffd92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
