{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81c9974d",
   "metadata": {},
   "source": [
    "# Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dd90b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 12:33:57.069906: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os, object_detection\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631ab706",
   "metadata": {},
   "source": [
    "## Set up file structure and download chosen base model from Model Zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d3c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"640x640_model\"\n",
    "pretrainedModel = \"ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8\"\n",
    "pretrainedModelURL = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\"\n",
    "\n",
    "# Script sourced from Tensorflow: https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/tensorflow-1.14/training.html\n",
    "tfRecordScript = \"generate_tfrecord.py\"\n",
    "labelMap = \"label_map.pbtxt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e92e56ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "filePaths = {\n",
    "    \"WORKSPACE\": os.path.join(\"TF\", \"workspace\"),\n",
    "    \"SCRIPTS\": os.path.join(\"TF\", \"scripts\"),\n",
    "    \"APIMODEL\": os.path.join(\"TF\", \"models\"),\n",
    "    \"ANNOTATIONS\": os.path.join(\"TF\", \"workspace\", \"annotations\"),\n",
    "    \"IMAGES\": os.path.join(\"TF\", \"workspace\", \"images\"),\n",
    "    \"PRETRAINED_MODELS\": os.path.join(\"TF\", \"workspace\", \"pretrained_models\"),\n",
    "    'MODELS': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'CHECKPOINTS': os.path.join('Tensorflow', 'workspace','models', modelName), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f3fe509",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', modelName, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(filePaths['SCRIPTS'], tfRecordScript),\n",
    "    'LABELMAP': os.path.join(filePaths['ANNOTATIONS'], labelMap)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb2641ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in filePaths.values():\n",
    "    !mkdir -p {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37aac0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'TF/models'...\n",
      "remote: Enumerating objects: 81991, done.\u001b[K\n",
      "remote: Counting objects: 100% (458/458), done.\u001b[K\n",
      "remote: Compressing objects: 100% (204/204), done.\u001b[K\n",
      "remote: Total 81991 (delta 293), reused 400 (delta 254), pack-reused 81533\u001b[K\n",
      "Receiving objects: 100% (81991/81991), 596.38 MiB | 5.53 MiB/s, done.\n",
      "Resolving deltas: 100% (58482/58482), done.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join(filePaths['APIMODEL'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {filePaths['APIMODEL']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a28dd9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-09 12:57:47--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.200.16, 2a00:1450:4009:81d::2010\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.200.16|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20518283 (20M) [application/x-tar]\n",
      "Saving to: ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’\n",
      "\n",
      "ssd_mobilenet_v2_fp 100%[===================>]  19.57M  34.4MB/s    in 0.6s    \n",
      "\n",
      "2023-03-09 12:57:48 (34.4 MB/s) - ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’ saved [20518283/20518283]\n",
      "\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "!wget {pretrainedModelURL}\n",
    "!mv {pretrainedModel+'.tar.gz'} {filePaths['PRETRAINED_MODELS']}\n",
    "!cd {filePaths['PRETRAINED_MODELS']} && tar -zxvf {pretrainedModel+'.tar.gz'}\n",
    "!cp {os.path.join(filePaths['PRETRAINED_MODELS'], pretrainedModel, 'pipeline.config')} {os.path.join(filePaths['CHECKPOINTS'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588dd71b",
   "metadata": {},
   "source": [
    "# Create label mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17b52410",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectLabels = [{'name':'resistor', 'id':1},\n",
    "                {'name':'electrolytic_capacitor', 'id':2},\n",
    "                {'name':'LED', 'id':3},\n",
    "                {'name':'ceramic_capacitor', 'id':4},\n",
    "                {'name':'IC', 'id':5}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in objectLabels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c837a6e9",
   "metadata": {},
   "source": [
    "## Convert XML to TF record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06b6b173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: TF/workspace/annotations/train.record\n",
      "Successfully created the TFRecord file: TF/workspace/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(filePaths['IMAGES'], 'train')} -l {files['LABELMAP']} -o {os.path.join(filePaths['ANNOTATIONS'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(filePaths['IMAGES'], 'test')} -l {files['LABELMAP']} -o {os.path.join(filePaths['ANNOTATIONS'], 'test.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1aa414",
   "metadata": {},
   "source": [
    "## Set up model config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd8d0617",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)\n",
    "    \n",
    "pipeline_config.model.ssd.num_classes = len(objectLabels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(filePaths['PRETRAINED_MODELS'], pretrainedModel, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(filePaths['ANNOTATIONS'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(filePaths['ANNOTATIONS'], 'test.record')]\n",
    "\n",
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
